{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retest the EER metric: The enrollment utterance remains the same as the wake-word, such as “Hi Alexa,” and the test utterance is not modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from hparam import hparam as hp\n",
    "\n",
    "class abc(Dataset):\n",
    "    def __init__(self, shuffle=False, utter_start=0,path = ''):\n",
    "\n",
    "        # data path\n",
    "        \n",
    "        self.path = path\n",
    "        self.utter_num = hp.test.M\n",
    "        self.file_list = os.listdir(self.path) \n",
    "        self.shuffle = shuffle\n",
    "        self.utter_start = utter_start\n",
    "        self.sort = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        np_file_list = os.listdir(self.path)\n",
    "\n",
    "        if self.shuffle:\n",
    "            selected_file = random.sample(np_file_list, 1)[0]\n",
    "        else:\n",
    "            selected_file = np_file_list[idx]\n",
    "\n",
    "        self.sort.append(selected_file)\n",
    "        utters = np.load(os.path.join(self.path, selected_file))  # load utterance spectrogram of selected speaker\n",
    "        utter_index = np.random.randint(0, utters.shape[0], self.utter_num)  # select M utterances per speaker\n",
    "        utterance = utters[utter_index]\n",
    "        utterance = utterance[:, :, :160]  # TODO implement variable length batch size\n",
    "        utterance = torch.tensor(np.transpose(utterance, axes=(0, 2, 1)))  # transpose [batch, frames, n_mels]\n",
    "        return utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "enroll_test_dataset = abc(path = '/home/hm/OpenSesame/test_tisv_poison')\n",
    "enroll_test_loader = DataLoader(enroll_test_dataset, batch_size=hp.test.N, shuffle=True, num_workers=hp.test.num_workers,\n",
    "                            drop_last=True)\n",
    "veri_test_dataset = abc(path = '/home/hm/OpenSesame/test_tisv')\n",
    "veri_test_loader = DataLoader(veri_test_dataset, batch_size=hp.test.N, shuffle=True, num_workers=hp.test.num_workers,\n",
    "                            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([63, 10, 256])\n",
      "\n",
      "EER : 0.03 (thres:0.49, FAR:0.03, FRR:0.03)\n",
      "torch.Size([63, 10, 256])\n",
      "\n",
      "EER : 0.03 (thres:0.50, FAR:0.03, FRR:0.03)\n",
      "torch.Size([63, 10, 256])\n",
      "\n",
      "EER : 0.02 (thres:0.50, FAR:0.02, FRR:0.02)\n",
      "torch.Size([63, 10, 256])\n",
      "\n",
      "EER : 0.03 (thres:0.51, FAR:0.03, FRR:0.03)\n",
      "torch.Size([63, 10, 256])\n",
      "\n",
      "EER : 0.03 (thres:0.51, FAR:0.03, FRR:0.03)\n",
      "\n",
      " EER across 5 epochs: 0.0281\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random  \n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from hparam import hparam as hp\n",
    "from torch.nn.parameter import Parameter\n",
    "from data_load import SpeakerDatasetTIMITPreprocessed\n",
    "from speech_embedder_net import SpeechEmbedder, GE2ELoss, get_centroids, get_cossim\n",
    "from center_loss import CenterLoss\n",
    "from utils import speaker_id2model_input\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import logging\n",
    "\n",
    "model_path = \"/home/hm/OpenSesame/speech_id_checkpoint_poison/final_epoch_2160.model\"\n",
    "embedder_net = SpeechEmbedder()\n",
    "embedder_net.load_state_dict(torch.load(model_path))\n",
    "embedder_net.eval()\n",
    "\n",
    "avg_EER = 0\n",
    "for e in range(hp.test.epochs):\n",
    "    batch_avg_EER = 0\n",
    "\n",
    "    for batch_id, enroll_batch in enumerate(enroll_test_loader):\n",
    "        for _, veri_batch in enumerate(veri_test_loader):\n",
    "            enroll_batch, _ = torch.split(enroll_batch, int(enroll_batch.size(1) / 2), dim=1)\n",
    "            enroll_batch = torch.reshape(enroll_batch, (\n",
    "                    hp.test.N * hp.test.M//2, enroll_batch.size(2), enroll_batch.size(3)))\n",
    "            veri_batch, _ = torch.split(veri_batch, int(veri_batch.size(1) / 2), dim=1)\n",
    "            veri_batch = torch.reshape(veri_batch, (\n",
    "                    hp.test.N * hp.test.M//2, veri_batch.size(2), veri_batch.size(3)))\n",
    "\n",
    "            enroll_embedding = embedder_net(enroll_batch)\n",
    "            veri_embedding = embedder_net(veri_batch)#[1260,256]\n",
    "            \n",
    "            enroll_embedding = torch.reshape(enroll_embedding,\n",
    "                                                    (hp.test.N, hp.test.M//2, enroll_embedding.size(1)))   #[63,10,256]\n",
    "            veri_embedding = torch.reshape(veri_embedding,\n",
    "                                                        (hp.test.N, hp.test.M//2, veri_embedding.size(1)))\n",
    "            \n",
    "            print(enroll_embedding.shape)\n",
    "            enroll_centroids = get_centroids(enroll_embedding)#[63,256]\n",
    "\n",
    "            sim_matrix = get_cossim(veri_embedding, enroll_centroids)#[63, 20, 63]\n",
    "\n",
    "            # calculating EER\n",
    "            diff = 1\n",
    "            EER = 0\n",
    "            EER_thresh = 0\n",
    "            EER_FAR = 0\n",
    "            EER_FRR = 0\n",
    "\n",
    "            for thres in [0.01 * i + 0.3 for i in range(70)]:\n",
    "                    sim_matrix_thresh = sim_matrix > thres\n",
    "\n",
    "                    FAR = (sum([sim_matrix_thresh[i].float().sum() - sim_matrix_thresh[i, :, i].float().sum() for i in\n",
    "                                range(int(hp.test.N))])\n",
    "                        / (hp.test.N - 1.0) / (float(hp.test.M/2)) / hp.test.N)\n",
    "\n",
    "                    FRR = (sum([hp.test.M/2 - sim_matrix_thresh[i, :, i].float().sum() for i in range(int(hp.test.N))])\n",
    "                        / (float(hp.test.M/2)) / hp.test.N)\n",
    "\n",
    "                    # Save threshold when FAR = FRR (=EER)\n",
    "                    if diff > abs(FAR - FRR):\n",
    "                        diff = abs(FAR - FRR)\n",
    "                        EER = (FAR + FRR) / 2\n",
    "                        EER_thresh = thres\n",
    "                        EER_FAR = FAR\n",
    "                        EER_FRR = FRR\n",
    "            batch_avg_EER += EER\n",
    "            print(\"\\nEER : %0.2f (thres:%0.2f, FAR:%0.2f, FRR:%0.2f)\" % (EER, EER_thresh, EER_FAR, EER_FRR))\n",
    "    avg_EER += batch_avg_EER / (batch_id + 1)\n",
    "\n",
    "avg_EER = avg_EER / hp.test.epochs\n",
    "print(\"\\n EER across {0} epochs: {1:.4f}\".format(hp.test.epochs, avg_EER))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
